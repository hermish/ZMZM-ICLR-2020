{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 Clean and Noisy Color Bases\n",
    "\n",
    "## 3.1 Imports & Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from PIL import Image\n",
    "from sklearn import feature_extraction\n",
    "\n",
    "from library import generator\n",
    "\n",
    "%config InlineBackend.figure_format='retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DUCK = 'images/duck.jpg'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_color_image(address):\n",
    "    image = Image.open(address)\n",
    "    pixels = np.array(image)\n",
    "    pixels = pixels.astype(np.float64)\n",
    "    return pixels\n",
    "\n",
    "def to_color_patches(pixels, patch_size):\n",
    "    slices = []\n",
    "    channels = pixels.shape[-1]\n",
    "    for channel in range(channels):\n",
    "        current = pixels[:,:,channel]\n",
    "        shaped_patches = feature_extraction.image.extract_patches_2d(current, patch_size)\n",
    "        patches = np.reshape(shaped_patches, (len(shaped_patches), -1)).T\n",
    "        slices.append(patches)\n",
    "    return np.vstack(slices)\n",
    "\n",
    "def patch_to_image(pixels, patch_size, channels):\n",
    "    channel_patches = np.split(pixels, channels)\n",
    "    for channel in range(channels):\n",
    "        channel_patches[channel] = np.reshape(channel_patches[channel], (patch_size, patch_size))\n",
    "    patch = np.dstack(channel_patches)\n",
    "    return patch\n",
    "\n",
    "def normalize_image(pixels):\n",
    "    pixels = np.maximum(pixels, 0)\n",
    "    pixels = np.minimum(pixels, 255)\n",
    "    return pixels / 255\n",
    "\n",
    "PIXEL_MAX = 255\n",
    "\n",
    "def mean_squared_error(first, second):\n",
    "    assert first.shape == second.shape\n",
    "    error = np.mean((first - second) ** 2)\n",
    "    return error\n",
    "\n",
    "def psnr(first, second):\n",
    "    error = mean_squared_error(first, second)\n",
    "    if error == 0.0:\n",
    "        return float('inf')\n",
    "    return 20 * np.log10(PIXEL_MAX) - 10 * np.log10(error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Figure Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "duck = read_color_image(DUCK)\n",
    "noisy_duck = duck + np.random.normal(scale=20, size=duck.shape)\n",
    "\n",
    "CHANNELS = 3\n",
    "PATCH_SIZE = 8\n",
    "\n",
    "clean_patches = to_color_patches(duck, (PATCH_SIZE, PATCH_SIZE))\n",
    "noisy_patches = to_color_patches(noisy_duck, (PATCH_SIZE, PATCH_SIZE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "### CLEAN DUCK\n",
    "\n",
    "fig = plt.figure(figsize=(64, 64))\n",
    "plt.imshow(normalize_image(duck))\n",
    "plt.axis('off')\n",
    "fig.savefig('03-duck.pdf', bbox_inches='tight')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "### NOISY DUCK\n",
    "\n",
    "fig = plt.figure(figsize=(64, 64))\n",
    "plt.imshow(normalize_image(noisy_duck))\n",
    "plt.axis('off')\n",
    "fig.savefig('03-noisy-duck.pdf', bbox_inches='tight')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## CLEAN DUCK BASES\n",
    "\n",
    "ITERATIONS = 100\n",
    "\n",
    "updates = generator.get_dictionary_learning_iterates(clean_patches)\n",
    "clean_dictionary = next(itertools.islice(updates, ITERATIONS, None))\n",
    "clean_dictionary = clean_dictionary.T\n",
    "\n",
    "clean_encoding = clean_dictionary.T @ clean_patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "norms = np.abs(clean_encoding)\n",
    "norms = np.sum(norms, axis=1)\n",
    "all_indices = list(range(len(norms)))\n",
    "all_indices.sort(key=lambda row: norms[row], reverse=True)\n",
    "\n",
    "sum_signs = np.sum(clean_encoding, axis=1)\n",
    "sum_signs = np.sign(sum_signs)\n",
    "\n",
    "ROWS, COLS = 3, 4\n",
    "\n",
    "fig, axs = plt.subplots(ROWS, COLS, figsize=(64, 48))\n",
    "plt.subplots_adjust(left=None, right=None, bottom=None, top=None, wspace=0.05, hspace=0.05)\n",
    "for index, ax in zip(all_indices, axs.flat):\n",
    "    base = clean_dictionary[:,index] * sum_signs[index]\n",
    "    base = base - base.min()\n",
    "    base = base / base.max()\n",
    "    base = patch_to_image(base, PATCH_SIZE, CHANNELS)\n",
    "    \n",
    "    ax.imshow(base)\n",
    "    ax.axis('off')\n",
    "fig.savefig('03-clean-bases.pdf', bbox_inches='tight')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## NOISY DUCK BASES\n",
    "\n",
    "ITERATIONS = 100\n",
    "\n",
    "updates = generator.get_dictionary_learning_iterates(noisy_patches)\n",
    "noisy_dictionary = next(itertools.islice(updates, ITERATIONS, None))\n",
    "noisy_dictionary = noisy_dictionary.T\n",
    "\n",
    "noisy_encoding = noisy_dictionary.T @ noisy_patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "norms = np.abs(noisy_encoding)\n",
    "norms = np.sum(norms, axis=1)\n",
    "all_indices = list(range(len(norms)))\n",
    "all_indices.sort(key=lambda row: norms[row], reverse=True)\n",
    "\n",
    "sum_signs = np.sum(noisy_encoding, axis=1)\n",
    "sum_signs = np.sign(sum_signs)\n",
    "\n",
    "ROWS, COLS = 3, 4\n",
    "\n",
    "fig, axs = plt.subplots(ROWS, COLS, figsize=(64, 48))\n",
    "plt.subplots_adjust(left=None, right=None, bottom=None, top=None, wspace=0.05, hspace=0.05)\n",
    "for index, ax in zip(all_indices, axs.flat):\n",
    "    base = noisy_dictionary[:,index] * sum_signs[index]\n",
    "    base = base - base.min()\n",
    "    base = base / base.max()\n",
    "    base = patch_to_image(base, PATCH_SIZE, CHANNELS)\n",
    "    \n",
    "    ax.imshow(base)\n",
    "    ax.axis('off')\n",
    "fig.savefig('03-noisy-bases.pdf', bbox_inches='tight')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4 Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SNR: 6.561430358886719\n"
     ]
    }
   ],
   "source": [
    "noise_stdev = 20\n",
    "snr_ratio = duck.mean() / noise_stdev\n",
    "print('SNR:', snr_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOP_BASES = 20\n",
    "\n",
    "norms = np.abs(clean_encoding)\n",
    "norms = np.sum(norms, axis=1)\n",
    "clean_priorities = list(range(len(norms)))\n",
    "clean_priorities.sort(key=lambda row: norms[row], reverse=True)\n",
    "\n",
    "norms = np.abs(noisy_encoding)\n",
    "norms = np.sum(norms, axis=1)\n",
    "noisy_priorities = list(range(len(norms)))\n",
    "noisy_priorities.sort(key=lambda row: norms[row], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.25095974 0.97816219 0.98908451 0.99712264 0.99999959]\n"
     ]
    }
   ],
   "source": [
    "base_angles = np.zeros((TOP_BASES, TOP_BASES))\n",
    "\n",
    "for row in range(TOP_BASES):\n",
    "    for col in range(TOP_BASES):\n",
    "        base_angles[row][col] = np.abs(noisy_dictionary[:,noisy_priorities[row]] @ \\\n",
    "                                       clean_dictionary[:,clean_priorities[col]])\n",
    "        \n",
    "top_angles = []\n",
    "for index in range(TOP_BASES):\n",
    "    top_angles.append(max(base_angles[index]))\n",
    "\n",
    "values = np.percentile(top_angles, [0, 25, 50, 75, 100])\n",
    "print(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
